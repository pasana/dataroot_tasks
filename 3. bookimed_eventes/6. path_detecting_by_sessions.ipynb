{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import copy\n",
    "import re\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domains = 'com|co.in|com.hk|de||co.uk|co.jp|fr|com.br|it|ru|es|ca|com.mx|co.id|com.tr|com.au|pl|com.sa|nl|com.ar|com.eg|co.th|com.pk|co.za|com.my|be|gr|com.vn|co.ve|com.tw|com.ua|at|se|com.co|ro|ch|pt|com.ph|cl|com.ng|com.sg|com.pe|ae|co.kr|co.hu|ie|dk|no|co.il|fi|cz|co.ma|sk|co.nz|com.kw|lk|bg|com.qa|az|kz|com.do|hr|by|com.ec|lt|iq|co.ke|com.bd|com.om|tn|si|co.cr|com.gt|com.pr|com.sv|lv|com.uy|jo|com.bo|ba|com.cu|rs|com.ly|cm|ee|co.ug|com.bh|com.np|com.gh|dz|lu|com.lb|co.uz|ci|com.py|com.ni|hn|com.et|tt|co.tz|mg|sn|cd|com.kh|am|com.af|ge|mu|com.bn|co.mz|com.jm|com.gi|is|com.pa|md|ps|com.na|mn|com.mt|co.bw|bj|kg|ml|rw|co.zm|bs|ht|la|com.bz|co.zw|as|cat|mk|ne|mw|tg|co.ao|gp|gy|bf|ga|li|co|tm|dj|mv|hk|sc|dm|bi|co.vi|vu|ad|com.vc|com.ag|com.fj|to|cf|fm|tk|gg|ws|vg|im|nu|gm|je|ms|me|co.im|tl|com.ai|gl|co.ls|co.je|st|it.ao|com.by|com.tj|pn|sh|com.sl|nr|sm|cg|co.ck|com.sb|com.cy|so|com.nf|com.ve|com.iq|jp|ac|com.tn|in|td'\n",
    "\n",
    "pattern = u'^http[s]*://(www.|www.clck.|ru.|go.|nova.|m.|r.search.|)(?P<ref>[\\w]+).(%s)(?P<tail>[\\w/=%%-]*)'%domains\n",
    "\n",
    "var_values = 'country|illness|direction|procedure|operation|city|%page'\n",
    "one_var_pattern = '(?P<head>/(clinics|treatment|doctors|cities|page)/)(?P<var>(%s))=[\\w]*'%var_values\n",
    "two_var_pattern = '(?P<head>/(clinics|treatment)/)(?P<var1>(%s))=[\\w]*/(?P<var2>(%s))=[\\w]*'%(var_values, var_values)\n",
    "object_pattern = '/(?P<var>(clinic|article|doctor|agency|program|diagnosticsKind|diagnostic|doc))/[\\w-]*'\n",
    "review_pattern = '/(?P<var>(review|diagnosticsKind|diagnostic|LK/request|clientLK/request|city|tprogram))/[0-9]*'\n",
    "\n",
    "this_path = './sessions'\n",
    "that_path = './paths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_relation_mat(data_t):\n",
    "    N=len(data_t)\n",
    "    r  = re.compile('^http[s]*://[ru.]*bookimed.com(?P<path>/[\\w/=-]*)')\n",
    "    mat = [[0]*N]*N\n",
    "    for i in range(0,N):\n",
    "        for j in range(i+1,N):\n",
    "            if data_t[j]['path']==data_t[i]['path'] and data_t[j]['referrer']==data_t[i]['referrer']:\n",
    "                if data_t[j]['type']==3:\n",
    "                    mat[i][j] = 2\n",
    "                    continue\n",
    "                if data_t[j]['type']==data_t[i]['type'] and data_t[i]['type']==1:\n",
    "                    d1 = copy.deepcopy(data_t[i])\n",
    "                    d2 = copy.deepcopy(data_t[j])\n",
    "                    #d1 = data_t[i].values()\n",
    "                    #d2 = data_t[j].values()\n",
    "                    if d1.pop('timestamp')!=d2.pop('timestamp'):\n",
    "                        d1.pop('userId')\n",
    "                        d2.pop('userId')\n",
    "                        try:\n",
    "                            d1.pop('originalTimestamp')\n",
    "                            d2.pop('originalTimestamp')\n",
    "                        except:\n",
    "                            pass\n",
    "                        if d1==d2:\n",
    "                            mat[i][j]=3\n",
    "                            continue\n",
    "                if data_t[j]['type']==2:\n",
    "                    if data_t[j]['event']==2:\n",
    "                        mat[i][j]=4\n",
    "                        continue\n",
    "                    if data_t[j]['event']==3:\n",
    "                        mat[i][j]=5\n",
    "                        continue\n",
    "                    if data_t[j]['event']==1:\n",
    "                        mat[i][j]=6\n",
    "                        continue\n",
    "            else:\n",
    "                try:\n",
    "                    ref = re.match(r, data_t[j]['referrer']).groupdict()['path'] \n",
    "                except:\n",
    "                    ref = data_t[j]['referrer']\n",
    "                if ref==data_t[i]['path']:\n",
    "                    mat[i][j] = 1\n",
    "                    continue\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_paths(mat_t):\n",
    "    N = len(mat_t)\n",
    "    paths = []\n",
    "    if N-1 == 0:\n",
    "        path = []\n",
    "        if data[0]['type']==1:\n",
    "            path+=[data[0]['path']]\n",
    "            try:\n",
    "                path+=[re.match(r, data[0]['referrer']).groupdict()['path'] ]\n",
    "            except:\n",
    "                path+=[data[0]['referrer']]\n",
    "        if data[0]['type']==3:\n",
    "            path+=['identify']\n",
    "        paths+=[path]\n",
    "    for j in range(N-1,0,-1):\n",
    "        i=N-1\n",
    "        path = []\n",
    "        while (i>0) and (j>=1):\n",
    "            #print j\n",
    "            if sum([k[j] for k in mat_t[0:i]])==0:\n",
    "                path += [data[j]['path']]\n",
    "                path += [data[j]['referrer']]\n",
    "                if j>1:\n",
    "                    break\n",
    "            for i in range(j-1,-1,-1):\n",
    "                #print \"\\t %d\" % i, mat_t[i][j]\n",
    "                if mat_t[i][j]==0:\n",
    "                    continue\n",
    "                if mat_t[i][j] == 1:\n",
    "                    path += [data[j]['path']]\n",
    "                    break\n",
    "                if mat_t[i][j] == 2:\n",
    "                    path += ['identify']\n",
    "                    break\n",
    "                if mat_t[i][j] == 3:\n",
    "                    #path += [data[j]['path']]\n",
    "                    break\n",
    "                    pass\n",
    "                if mat_t[i][j] == 4:\n",
    "                    path += [u'Requested Treatment']\n",
    "                    break\n",
    "                if mat_t[i][j] == 5:\n",
    "                    path += [u'Requested Callback']\n",
    "                    break\n",
    "                if mat_t[i][j] == 6:\n",
    "                    #print data[j]\n",
    "                    path += [data[j]['properties']['button_type']]\n",
    "                    break                  \n",
    "            if i==0:\n",
    "                if data[0]['type']==1:\n",
    "                    path+=[data[0]['path']]\n",
    "                    try:\n",
    "                        path+=[re.match(r, data[0]['referrer']).groupdict()['path'] ]\n",
    "                    except:\n",
    "                        path+=[data[0]['referrer']]\n",
    "                if data[0]['type']==3:\n",
    "                    path+=['identify']\n",
    "            j=i\n",
    "            #print \"\\t \\t\" ,i,j, b\n",
    "            #print (i!=0 or j!=1), '=', (i!=0), (j!=1)\n",
    "        paths += [path]\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_paths(paths_t):\n",
    "    inds=[]\n",
    "    paths=sorted(paths_t, key=lambda x: len(x),reverse=True)\n",
    "    for i in range(len(paths)-1,-1,-1):\n",
    "        for j in range(i-1,-1,-1):\n",
    "            l = len(paths[j]) - len(paths[i])\n",
    "            if paths[j][l:]==paths[i]:\n",
    "                inds+=[i]\n",
    "                break\n",
    "    for i in inds:\n",
    "        tenp=paths.pop(i)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simplify_path(paths_t):\n",
    "    for path in paths_t:\n",
    "        for i in range(0, len(path)):\n",
    "            try:\n",
    "                ref = re.match(pattern, path[i]).groupdict()['ref']\n",
    "                if ref == 'bookimed':\n",
    "                    path[i] = re.match(pattern, path[i]).groupdict()['tail']\n",
    "                else:\n",
    "                    path[i] = ref\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                temp = re.match(object_pattern, path[i]).groupdict()\n",
    "                path[i] = '/' + temp['var'] +'/'+ temp['var'] + '_name/'\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                temp = re.match(review_pattern, path[i]).groupdict()\n",
    "                path[i] = '/' + temp['var'] +'/num/'\n",
    "            except:\n",
    "                pass        \n",
    "            try:\n",
    "                temp = re.match(two_var_pattern, path[i]).groupdict()\n",
    "                path[i] = temp['head']+temp['var1']+'/'+temp['var2']+'/'\n",
    "            except:\n",
    "                try:\n",
    "                    temp = re.match(one_var_pattern, path[i]).groupdict()\n",
    "                    path[i] = temp['head']+temp['var']+'/'\n",
    "                except:\n",
    "                    pass\n",
    "            if '?' in str(path[i]):\n",
    "                path[i] = path[i][:path[i].index('?')]\n",
    "    return paths_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paths_to_str(paths_t):\n",
    "    str_paths = []\n",
    "    for i in paths_t:\n",
    "        str_paths += [' , '.join(list(reversed(i)))]\n",
    "    return str_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def paths_extract(l,r):\n",
    "    for file_name in files[l:r]:\n",
    "        f = open('%s/%s'%(this_path,file_name))\n",
    "        context = f.readlines()\n",
    "        data = []\n",
    "        for i in context[:]:\n",
    "            try:\n",
    "                data += [json.loads(i.replace(',\\n','').replace('\\n',''))]\n",
    "            except:\n",
    "                pass\n",
    "        data=sorted(data, key=lambda x: x['timestamp'])\n",
    "        for path in paths_to_str(simplify_path(filter_paths(get_paths(get_relation_mat(data))))):\n",
    "            output.write(path.encode('utf-8') + '\\n')\n",
    "            all_paths += [path]\n",
    "        f.close()\n",
    "    print \"Done %d - %d\" %(l,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = [os.path.basename(x) for x in glob.glob('%s/*.json'%this_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n",
      "+1\n"
     ]
    }
   ],
   "source": [
    "#all_paths = []\n",
    "for file_name in files[:]:\n",
    "    i_f = open('%s/%s'%(this_path, file_name))\n",
    "    o_f = open('%s/%s'%(that_path, file_name), 'w+')\n",
    "    context = i_f.readlines()\n",
    "    data = []\n",
    "    for i in context[:]:\n",
    "        try:\n",
    "            data += [json.loads(i.replace(',\\n','').replace('\\n',''))]\n",
    "        except:\n",
    "            pass\n",
    "    data=sorted(data, key=lambda x: x['timestamp'])\n",
    "    for path in paths_to_str(simplify_path(filter_paths(get_paths(get_relation_mat(data))))):\n",
    "        o_f.write(path.encode('utf-8') + '\\n')\n",
    "        #all_paths += [path]\n",
    "    #output.write('%s \\n------------\\n'%file_name)\n",
    "    o_f.close()\n",
    "    i_f.close()\n",
    "    if files.index(file_name)%10000==0:\n",
    "        print \"+1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts = []\n",
    "l_files = len(files)/100\n",
    "N = 100\n",
    "for i in range(0,N):\n",
    "    ts += [threadinging.Thread(target=paths_extract, args=(l_files*i/N,l_files*(i+1)/N))]\n",
    "\n",
    "for t in ts:\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(all_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srt = sorted(list(set(all_paths)), key = lambda x: all_paths.count(x), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('%s/%s'%(this_path,files[-5]))\n",
    "context = f.readlines()\n",
    "data = []\n",
    "for i in context[:]:\n",
    "    try:\n",
    "        data += [json.loads(i.replace(',\\n','').replace('\\n',''))]\n",
    "    except:\n",
    "        pass\n",
    "data=sorted(data, key=lambda x: x['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paths_to_str(simplify_path(filter_paths(get_paths(get_relation_mat(data)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_relation_mat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_paths(get_relation_mat(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_paths(get_paths(get_relation_mat(data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
