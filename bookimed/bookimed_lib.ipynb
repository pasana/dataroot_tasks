{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_1 = './max/'\n",
    "path_2 = './max20160907'\n",
    "\n",
    "this_path = path_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_X_y_from(t_extract_data, t_data, t_estims_data):\n",
    "    clinic_ids = [i['id'] for i in t_data]\n",
    "    t_cleaned_data = [t_extract_data(t_data[clinic_ids.index(i['id'])], i) for i in t_estims_data]\n",
    "    X = sum([i[0] for i in t_cleaned_data],[])\n",
    "    y = sum([i[1] for i in t_cleaned_data],[])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_X_from(t_data):\n",
    "    t_cleaned_data = []\n",
    "    clinic_names = []\n",
    "    ids = []\n",
    "    for i in t_data:\n",
    "        if i['doctors']!=[]:\n",
    "            t_cleaned_data += [extract_data(i,[])]\n",
    "            clinic_names += [unicode(i['name_ru'])] * len(i['doctors'])\n",
    "            ids += [int(i['id'])] * len(i['doctors'])\n",
    "    X = sum([i for i in t_cleaned_data],[])\n",
    "    return X, clinic_names, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_with(X,y, info=False, short=False, return_short = False, new_coef = [], ts=0.2):\n",
    "    train_X, test_X, train_y, test_y = cross_validation.train_test_split(X, y, test_size = ts, random_state = 3)\n",
    "    regr = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "    if new_coef != []:\n",
    "        print \"new coefs\"\n",
    "        regr.coef_ = new_coef\n",
    "    regr.fit(train_X, train_y)\n",
    "    if info:\n",
    "        print \"Total: %d, train: %d, test: %d\" %(len(X), len(train_X), len(test_X))\n",
    "        print(\"Residual sum of squares: %.2f\"% np.mean((regr.predict(test_X) - test_y) ** 2))\n",
    "        print(\"Train absolute: %.2f\"% np.mean(abs(regr.predict(train_X) - train_y)))\n",
    "        print(\"Test absolute: %.2f\"% np.mean(abs(regr.predict(test_X) - test_y)))\n",
    "        print(\"Absolute to mean: %.2f%%\"% (np.mean(abs(regr.predict(test_X) - test_y))/np.mean(test_y)*100))\n",
    "        print('Train variance score: %.2f' % regr.score(train_X, train_y))\n",
    "        print('Test variance score: %.2f' % regr.score(test_X, test_y))\n",
    "    if short:\n",
    "        print \"Total: %d, train: %d, test: %d\" %(len(X), len(train_X), len(test_X))\n",
    "        print \"%.3f\" % np.mean(abs(regr.predict(train_X) - train_y))\n",
    "        print \"%.3f\" % np.mean(abs(regr.predict(test_X) - test_y))\n",
    "        print \"%.3f\" % (np.mean(abs(regr.predict(test_X) - test_y))/np.mean(test_y)*100)\n",
    "        print \"%.3f\" % regr.score(train_X, train_y)\n",
    "        print \"%.3f\" % regr.score(test_X, test_y)\n",
    "    if return_short:\n",
    "        return np.mean(abs(regr.predict(test_X) - test_y)),regr.score(test_X, test_y)\n",
    "    for i in regr.coef_:\n",
    "        print \"%.3f\" % i\n",
    "    #print \"%.3f\" % regr.intercept_\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pack(X, gd, ed, gp):\n",
    "    new_X = []\n",
    "    for x in X:\n",
    "        new_X+= [sum([\n",
    "            [round(sum(np.array(gd)*np.array(x[0:7])),5)],\n",
    "            [round(sum(np.array(ed)*np.array(x[7:12])),5)],\n",
    "            [round(sum(np.array(gp)*np.array(x[12:16])),5)],\n",
    "            x[16:]\n",
    "        ],[])]\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_procent(input_array):\n",
    "    new_pos=np.array(input_array)\n",
    "    straight = np.array([i for i in range(max(new_pos), min(new_pos)-1, -1)])\n",
    "    inversions = abs(straight - new_pos)\n",
    "    while not np.array_equal(inversions, np.zeros(len(inversions))):\n",
    "        new_pos=np.delete(new_pos, inversions.argmax())\n",
    "        new_pos = [10 - sorted(new_pos, reverse=True).index(x) for x in new_pos]\n",
    "        straight = np.array([i for i in range(max(new_pos), min(new_pos)-1, -1)])\n",
    "        inversions = abs(straight - new_pos)\n",
    "    return 100*len(new_pos)/float(len(input_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_X_sets(extract_data):\n",
    "    X_all, y_all = [], []\n",
    "\n",
    "    this_path = path_2\n",
    "    with open('./max/estims.json') as data_file: \n",
    "        estims_data = json.load(data_file)[2]['clinics']\n",
    "    with open('%s/меланома_все.json'%this_path) as data_file: #2\n",
    "        cancer_data = json.load(data_file)[0]['clinics']\n",
    "    X_1, y_1 = get_X_y_from(extract_data, cancer_data, estims_data)\n",
    "    X_all+=X_1\n",
    "    y_all+=y_1\n",
    "\n",
    "    with open('./max/estims.json') as data_file: \n",
    "        estims_data = json.load(data_file)[0]['clinics']\n",
    "    with open('%s/рак_груди_все.json'%this_path) as data_file: #0\n",
    "        cancer_data = json.load(data_file)[0]['clinics']\n",
    "    X_2, y_2 = get_X_y_from(extract_data, cancer_data, estims_data)\n",
    "    X_all+=X_2\n",
    "    y_all+=y_2\n",
    "\n",
    "    with open('./max/estims.json') as data_file: \n",
    "        estims_data = json.load(data_file)[4]['clinics']    \n",
    "    with open('%s/рак_простаты_все.json'%this_path) as data_file: #4\n",
    "        cancer_data = json.load(data_file)[0]['clinics']\n",
    "    clinic_ids = [i['id'] for i in estims_data]\n",
    "    estims_data.pop(clinic_ids.index('0'))\n",
    "    X_3, y_3 = get_X_y_from(extract_data, cancer_data, estims_data)\n",
    "    X_all+=X_3\n",
    "    y_all+=y_3\n",
    "\n",
    "    with open('./max/estims.json') as data_file: \n",
    "        estims_data = json.load(data_file)[1]['clinics']     \n",
    "    with open('%s/рак_шейки_матки_все.json'%this_path) as data_file: #1\n",
    "        cancer_data = json.load(data_file)[0]['clinics']\n",
    "    X_4, y_4 = get_X_y_from(extract_data, cancer_data, estims_data)\n",
    "    X_all+=X_4\n",
    "    y_all+=y_4\n",
    "\n",
    "    with open('./max/estims.json') as data_file: \n",
    "        estims_data = json.load(data_file)[3]['clinics']         \n",
    "    with open('%s/рак_щитовидки_все.json'%this_path) as data_file: #3\n",
    "        cancer_data = json.load(data_file)[0]['clinics']\n",
    "    X_5, y_5 = get_X_y_from(extract_data, cancer_data, estims_data)\n",
    "    X_all+=X_5\n",
    "    y_all+=y_5\n",
    "    \n",
    "    return X_all, X_1, X_2, X_3, X_4, X_5, y_all, y_1, y_2, y_3, y_4, y_5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
