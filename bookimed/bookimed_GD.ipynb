{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"deg\",\n",
    "    \"top\", \n",
    "    \"illn\", \n",
    "    \"lang\",\n",
    "#    \"ad_spec\",\n",
    "    \"h_index\",\n",
    "    \"exp_doc\", \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cancer_data[0]['doctors'][0]['languages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in cancer_data:\n",
    "    try:\n",
    "        for j in i['doctors']:\n",
    "            try:\n",
    "                print [int(k['id']) for k in j['languages']]\n",
    "                print in [int(k['id']) for k in j['languages']]\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clinic_ids = [i['id'] for i in estims_data]\n",
    "#estims_data.pop(clinic_ids.index('0'))\n",
    "#print sorted(clinic_ids)\n",
    "#print sorted([i['id'] for i in cancer_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_data(clinic, clinic_estim):\n",
    "    all_proc = clinic['procedures']['diagnostics'] + clinic['procedures']['operations']\n",
    "    all_doc = clinic['doctors']\n",
    "    X = []\n",
    "    for doc in all_doc:\n",
    "        X+=[[]]\n",
    "        X[-1]+=[doc['degree'].count(u'Профессор')]    #doctor_prof_count\n",
    "        X[-1]+=[int(doc['top'])]\n",
    "        X[-1]+=[len(doc['illnesses'])]\n",
    "        X[-1]+=[len(doc['languages'])]\n",
    "#        X[-1]+=[0]\n",
    "#        if len(doc['languages']) > 0:\n",
    "#            lang=[int(k['id']) for k in doc['languages']]\n",
    "#            if 1 in lang:\n",
    "#                X[-1][-1]+=0.8\n",
    "#            if 2 in lang:\n",
    "#                X[-1][-1]+=0.2\n",
    "        X[-1]+=[int(doc['h_index'])]\n",
    "        X[-1]+=[int(doc['experience'])]\n",
    "    y=[int(clinic_estim['specialist'])] * len(all_doc)\n",
    "    return [X, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_X_y_from(t_data):\n",
    "    clinic_ids = [i['id'] for i in t_data]\n",
    "    t_cleaned_data = [extract_data(cancer_data[clinic_ids.index(i['id'])], i) for i in estims_data]\n",
    "    X = sum([i[0] for i in t_cleaned_data],[])\n",
    "    y = sum([i[1] for i in t_cleaned_data],[])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normale(mat):\n",
    "    #for i in [2,4,5]:#lang\n",
    "    for i in [2,3,4]:#no lang\n",
    "        mass = [k[i] for k in mat]\n",
    "        m = max(mass)\n",
    "        if m>0:\n",
    "            for j in mat:\n",
    "                j[i] = round(j[i] / float(m), 4)\n",
    "    #return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_with(X,y, info=False, short=False, return_short = False, new_coef = [], ts=0.2):\n",
    "    train_X, test_X, train_y, test_y = cross_validation.train_test_split(X, y, test_size = ts, random_state = 3)\n",
    "    regr = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "    if new_coef != []:\n",
    "        print \"new coefs\"\n",
    "        regr.coef_ = new_coef\n",
    "    regr.fit(train_X, train_y)\n",
    "    if info:\n",
    "        print \"Total: %d, train: %d, test: %d\" %(len(X), len(train_X), len(test_X))\n",
    "        print(\"Residual sum of squares: %.2f\"% np.mean((regr.predict(test_X) - test_y) ** 2))\n",
    "        print(\"Train absolute: %.2f\"% np.mean(abs(regr.predict(train_X) - train_y)))\n",
    "        print(\"Test absolute: %.2f\"% np.mean(abs(regr.predict(test_X) - test_y)))\n",
    "        print(\"Absolute to mean: %.2f%%\"% (np.mean(abs(regr.predict(test_X) - test_y))/np.mean(test_y)*100))\n",
    "        print('Train variance score: %.2f' % regr.score(train_X, train_y))\n",
    "        print('Test variance score: %.2f' % regr.score(test_X, test_y))\n",
    "    if short:\n",
    "        print \"Total: %d, train: %d, test: %d\" %(len(X), len(train_X), len(test_X))\n",
    "        print \"%.3f\" % np.mean(abs(regr.predict(train_X) - train_y))\n",
    "        print \"%.3f\" % np.mean(abs(regr.predict(test_X) - test_y))\n",
    "        print \"%.3f\" % (np.mean(abs(regr.predict(test_X) - test_y))/np.mean(test_y)*100)\n",
    "        print \"%.3f\" % regr.score(train_X, train_y)\n",
    "        print \"%.3f\" % regr.score(test_X, test_y)\n",
    "    if return_short:\n",
    "        return np.mean(abs(regr.predict(test_X) - test_y)),regr.score(test_X, test_y)\n",
    "    for i in regr.coef_:\n",
    "        print \"%.3f\" % i\n",
    "    print \"%.3f\" % regr.intercept_\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all, y_all = [], []\n",
    "\n",
    "with open('./max/estims.json') as data_file: \n",
    "    estims_data = json.load(data_file)[2]['clinics']\n",
    "with open('./max/меланома_все.json') as data_file: #2\n",
    "    cancer_data = json.load(data_file)[0]['clinics']\n",
    "X_1, y_1 = get_X_y_from(cancer_data)\n",
    "X_all+=X_1\n",
    "y_all+=y_1\n",
    "    \n",
    "with open('./max/estims.json') as data_file: \n",
    "    estims_data = json.load(data_file)[0]['clinics']\n",
    "with open('./max/рак_груди_все.json') as data_file: #0\n",
    "    cancer_data = json.load(data_file)[0]['clinics']\n",
    "X_2, y_2 = get_X_y_from(cancer_data)\n",
    "X_all+=X_2\n",
    "y_all+=y_2\n",
    "    \n",
    "with open('./max/estims.json') as data_file: \n",
    "    estims_data = json.load(data_file)[4]['clinics']    \n",
    "with open('./max/рак_простаты_все.json') as data_file: #4\n",
    "    cancer_data = json.load(data_file)[0]['clinics']\n",
    "clinic_ids = [i['id'] for i in estims_data]\n",
    "estims_data.pop(clinic_ids.index('0'))\n",
    "X_3, y_3 = get_X_y_from(cancer_data)\n",
    "X_all+=X_3\n",
    "y_all+=y_3\n",
    "\n",
    "with open('./max/estims.json') as data_file: \n",
    "    estims_data = json.load(data_file)[1]['clinics']     \n",
    "with open('./max/рак_шейки_матки_все.json') as data_file: #1\n",
    "    cancer_data = json.load(data_file)[0]['clinics']\n",
    "X_4, y_4 = get_X_y_from(cancer_data)\n",
    "X_all+=X_4\n",
    "y_all+=y_4\n",
    "    \n",
    "with open('./max/estims.json') as data_file: \n",
    "    estims_data = json.load(data_file)[3]['clinics']         \n",
    "with open('./max/рак_щитовидки_все.json') as data_file: #3\n",
    "    cancer_data = json.load(data_file)[0]['clinics']\n",
    "X_5, y_5 = get_X_y_from(cancer_data)\n",
    "X_all+=X_5\n",
    "y_all+=y_5\n",
    "\n",
    "normale(X_all)\n",
    "normale(X_1)\n",
    "normale(X_2)\n",
    "normale(X_3)\n",
    "normale(X_4)\n",
    "normale(X_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = get_X_y_from(cancer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[i[-2] for i in X_all]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 8, train: 7, test: 1\n",
      "0.192\n",
      "1.392\n",
      "15.469\n",
      "0.736\n",
      "0.000\n",
      "1.006\n",
      "-0.693\n",
      "0.001\n",
      "-0.000\n",
      "-0.644\n",
      "0.029\n",
      "8.215\n",
      "\n",
      "Total: 8, train: 6, test: 2\n",
      "0.000\n",
      "3.059\n",
      "35.993\n",
      "1.000\n",
      "-38.598\n",
      "-1.032\n",
      "-4.317\n",
      "1.905\n",
      "0.000\n",
      "5.001\n",
      "0.024\n",
      "7.921\n",
      "\n",
      "Total: 8, train: 5, test: 3\n",
      "0.000\n",
      "2.587\n",
      "29.852\n",
      "1.000\n",
      "-32.746\n",
      "-2.675\n",
      "-2.675\n",
      "1.905\n",
      "0.000\n",
      "5.001\n",
      "0.024\n",
      "7.921\n",
      "\n",
      "Total: 8, train: 4, test: 4\n",
      "0.000\n",
      "0.500\n",
      "5.882\n",
      "1.000\n",
      "-1.000\n",
      "0.000\n",
      "0.000\n",
      "-0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "9.000\n",
      "\n",
      "Total: 8, train: 4, test: 4\n",
      "0.000\n",
      "0.500\n",
      "5.882\n",
      "1.000\n",
      "-1.000\n",
      "0.000\n",
      "0.000\n",
      "-0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "9.000\n",
      "\n",
      "Total: 8, train: 3, test: 5\n",
      "0.000\n",
      "0.400\n",
      "4.651\n",
      "1.000\n",
      "-0.667\n",
      "0.000\n",
      "0.000\n",
      "-0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "9.000\n",
      "\n",
      "Total: 8, train: 2, test: 6\n",
      "0.000\n",
      "0.333\n",
      "3.846\n",
      "1.000\n",
      "-0.500\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "9.000\n",
      "\n",
      "Total: 8, train: 1, test: 7\n",
      "0.000\n",
      "0.286\n",
      "3.279\n",
      "1.000\n",
      "-0.400\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "9.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-e4ff7f70d843>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mregr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-89a5f24cfef4>\u001b[0m in \u001b[0;36mprocess_with\u001b[1;34m(X, y, info, short, return_short, new_coef, ts)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"new coefs\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_coef\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Total: %d, train: %d, test: %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 427\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    413\u001b[0m                              \u001b[1;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[1;32m--> 415\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    regr = process_with(X_5, y_5, short=True, ts=i/10.0)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 8, train: 7, test: 1\n",
      "Residual sum of squares: 1.94\n",
      "Train absolute: 0.19\n",
      "Test absolute: 1.39\n",
      "Absolute to mean: 15.47%\n",
      "Train variance score: 0.74\n",
      "Test variance score: 0.00\n",
      "1.006\n",
      "-0.693\n",
      "0.001\n",
      "-0.000\n",
      "-0.644\n",
      "0.029\n",
      "8.215\n"
     ]
    }
   ],
   "source": [
    "regr = process_with(X_5, y_5, info=True, ts=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for i in range(0,len(y_2)):\n",
    "    print \"Real: %f \\t Predicted: %f\" %(y_2[i], regr.predict(X_2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "6\n",
      "1.0057\n",
      "-0.693\n",
      "0.0005\n",
      "-0.0\n",
      "-0.6442\n",
      "0.0293\n",
      "8.21512214126\n"
     ]
    }
   ],
   "source": [
    "print \"Features sorted by their score:\"\n",
    "#f = sorted(zip(map(lambda x: round(x, 4), regr.coef_), FEATURES), reverse=True)\n",
    "f = zip(map(lambda x: round(x, 4), regr.coef_), FEATURES)\n",
    "print len(FEATURES)\n",
    "for i in f:\n",
    "    #print \"%4f \\t %s\" %(i[0], i[1])\n",
    "    print i[0]\n",
    "print regr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "f = sorted(zip(map(lambda x: round(x, 4), regr.coef_), FEATURES), reverse=True)\n",
    "ind = [map(lambda x: x[1], f).index(i) for i in FEATURES]\n",
    "for i in ind:\n",
    "    print i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(sorted([i[5] for i in X_all]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
